# ğŸ”¹ FILE: app/services/scraper/save.py
# ==============================================================
# AUJI â€“ Save Jobs Helpers (SQLModel)
# - Upsert (no mass-delete): ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ detail_url / apply_url / url + source
# - ÙŠØ­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ø§Ù„ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© ÙˆÙŠØ­Ø¯Ù‘Ø« Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© Ø¨Ø¯Ù„ Ù…Ø§ ÙŠÙ…Ø³Ø­ Ø§Ù„ÙƒÙ„
# - Ù…ØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù‚Ø¯ÙŠÙ…: Ù†ÙØ³ Ø§Ù„ØªÙˆÙ‚ÙŠØ¹ save_jobs(items, session)
# - Ù…Ø¶Ø§Ù: save_jobs_bulk(items) Ù„Ø±Ø§Ø­Ø© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¨Ø¯ÙˆÙ† ØªÙ…Ø±ÙŠØ± Session
# ==============================================================

from typing import List, Any, Optional
from sqlmodel import Session, select
from app.models import Job
from app.db import get_session


def _find_existing_job(session: Session, item: dict) -> Optional[Job]:
    """
    ÙŠØ­Ø§ÙˆÙ„ Ø¥ÙŠØ¬Ø§Ø¯ Ø³Ø¬Ù„ Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰:
    1) detail_url
    2) apply_url
    3) url (Ù„Ù„ØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù‚Ø¯ÙŠÙ…)
    + Ù†ÙØ³ Ø§Ù„Ù…ØµØ¯Ø± (Ù„Ùˆ Ù…ØªØ§Ø­)
    """
    source = item.get("source")
    detail_url = item.get("detail_url")
    apply_url = item.get("apply_url")
    legacy_url = item.get("url")

    # Ø¨Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©: detail_url
    if detail_url:
        stmt = select(Job).where(Job.detail_url == detail_url)
        if source:
            stmt = stmt.where(Job.source == source)
        found = session.exec(stmt).first()
        if found:
            return found

    # Ø¨Ø¹Ø¯Ù‡: apply_url
    if apply_url:
        stmt = select(Job).where(Job.apply_url == apply_url)
        if source:
            stmt = stmt.where(Job.source == source)
        found = session.exec(stmt).first()
        if found:
            return found

    # Ø£Ø®ÙŠØ±Ù‹Ø§: legacy url
    if legacy_url:
        stmt = select(Job).where(Job.url == legacy_url)
        if source:
            stmt = stmt.where(Job.source == source)
        found = session.exec(stmt).first()
        if found:
            return found

    return None


def _update_job_fields(dest: Job, src: dict) -> None:
    """
    ÙŠØ­Ø¯Ù‘Ø« Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ø¢ØªÙŠØ© ÙÙ‚Ø· Ø¥Ù† ÙƒØ§Ù†Øª Ù‚ÙŠÙ…Ø© Ø¬Ø¯ÙŠØ¯Ø© Ù…ØªÙˆÙØ±Ø©:
    """
    updatable = [
        "title",
        "company",
        "location",
        "description",
        "detail_url",
        "apply_url",
        "url",           # Ù„Ù„ØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù‚Ø¯ÙŠÙ…
        "source",
        "category",
        "posted_at",
    ]
    for key in updatable:
        val = src.get(key)
        if val not in (None, ""):
            setattr(dest, key, val)


def save_jobs(items: List[Any], session: Session) -> int:
    """
    âœ… Ø³Ù„ÙˆÙƒ Ø¬Ø¯ÙŠØ¯: Upsert Ø¨Ø¯ÙˆÙ† Ù…Ø³Ø­ Ø´Ø§Ù…Ù„
    - ÙŠØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø¹Ù†Ø§ØµØ± ØºÙŠØ± Ø§Ù„ØµØ­ÙŠØ­Ø©
    - ÙŠØ¯Ø±Ø¬ Ø³Ø¬Ù„Ø§Øª Ø¬Ø¯ÙŠØ¯Ø© ÙˆÙŠØ­Ø¯Ù‘Ø« Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©
    - ÙŠØ±Ø¬Ù‘Ø¹ Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…ØªØ£Ø«Ø±Ø© (Ù…Ø¶Ø§ÙØ© + Ù…Ø­Ø¯Ù‘Ø«Ø©)
    """
    if not items:
        return 0

    affected = 0

    for raw in items:
        if not isinstance(raw, dict):
            # Ù„Ùˆ Ù„Ø£ÙŠ Ø³Ø¨Ø¨ Ø¹Ù†ØµØ± Ù…Ø´ dictØŒ ØªØ¬Ø§Ù‡Ù„Ù‡
            continue

        # Ø¶Ù…Ø§Ù† ÙˆØ¬ÙˆØ¯ source (Ø§ÙØªØ±Ø§Ø¶ÙŠÙ‹Ø§ vodafone Ù„ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù…ØµØ¯Ø±)
        if not raw.get("source"):
            raw["source"] = "vodafone"

        # Ù„Ø§Ø²Ù… ÙŠØ¨Ù‚Ù‰ ÙÙŠÙ‡ ÙˆØ§Ø­Ø¯Ø© Ù…Ù† Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ù„ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø³Ø¬Ù„
        if not (raw.get("detail_url") or raw.get("apply_url") or raw.get("url")):
            continue

        exists = _find_existing_job(session, raw)
        if exists:
            _update_job_fields(exists, raw)
            affected += 1
        else:
            session.add(Job(**raw))
            affected += 1

    session.commit()
    return affected


# ğŸ†• Ø±Ø§Ø­Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù…: Ù†ÙØ³ Ø§Ù„Ù…Ù†Ø·Ù‚ Ù„ÙƒÙ† Ø¨ÙŠØ¯ÙŠØ± Ø§Ù„Ù€ Session Ø¯Ø§Ø®Ù„ÙŠÙ‹Ø§
def save_jobs_bulk(items: List[Any]) -> int:
    """
    Wrapper Ù…Ø±ÙŠØ­: ÙŠÙØªØ­ Session Ø¯Ø§Ø®Ù„ÙŠÙ‹Ø§ ÙˆÙŠÙ†Ø§Ø¯ÙŠ save_jobs(items, session)
    """
    with next(get_session()) as db:
        return save_jobs(items, db)
